{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Baye's Classifier\n",
    "It is a classification technique based on Bayes’ Theorem with an assumption of independence among predictors. In simple terms, a Naive Bayes classifier assumes that the presence of a particular feature in a class is unrelated to the presence of any other feature.\n",
    "### Baye's Theorem :\n",
    "<code>P(A|B)=P(B|A)*P(A)/P(B)</code>\n",
    " <br>P(A|B) => probability of event A given that event B has already accured \n",
    "1. P(A|B) is the posterior probability of class (A, target) given predictor (B, attributes).\n",
    "2. P(A) is the prior probability of class.\n",
    "3. P(B|A) is the likelihood which is the probability of predictor given class.\n",
    "4. P(B) is the prior probability of predictor.(marginal probability)\n",
    "**Also** : P(A|B)*P(B)=P(A&B)\n",
    "### There are 3 types of Naive Bayes Classifiers :\n",
    "1. **Bernoulli Naive Bayes** : It assumes that all our features are binary such that they take only two values. Means 0s can represent “word does not occur in the document” and 1s as \"word occurs in the document\" .\n",
    "\n",
    "2. **Multinomial Naive Bayes** : Its is used when we have discrete data (e.g. movie ratings ranging 1 and 5 as each rating will have certain frequency to represent). In text learning we have the count of each word to predict the class or label.\n",
    "\n",
    "3. **Gaussian Naive Bayes** : Because of the assumption of the normal distribution, Gaussian Naive Bayes is used in cases when all our features are continuous. For example in Iris dataset features are sepal width, petal width, sepal length, petal length. So its features can have different values in data set as width and length can vary. We can’t represent features in terms of their occurrences. This means data is continuous. Hence we use Gaussian Naive Bayes here.\n",
    "#### Cons:\n",
    "1. If categorical variable has a category (in test data set), which was not observed in training data set, then model will assign a 0 (zero) probability and will be unable to make a prediction. This is often known as “Zero Frequency”. To solve this, we can use the smoothing technique. One of the simplest smoothing techniques is called Laplace estimation.\n",
    "2. Another limitation of Naive Bayes is the assumption of independent predictors. In real life, it is almost impossible that we get a set of predictors which are completely independent.\n",
    "\n",
    "<br>link : https://www.analyticsvidhya.com/blog/2017/09/naive-bayes-explained/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as na\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width      species\n",
       "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
       "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
       "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
       "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
       "4           5.0          3.6           1.4          0.2  Iris-setosa"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('C:/Users/vikash arya/datascience/datascience_krishnaik/data_sets/IRIS.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width         species\n",
       "145           6.7          3.0           5.2          2.3  Iris-virginica\n",
       "146           6.3          2.5           5.0          1.9  Iris-virginica\n",
       "147           6.5          3.0           5.2          2.0  Iris-virginica\n",
       "148           6.2          3.4           5.4          2.3  Iris-virginica\n",
       "149           5.9          3.0           5.1          1.8  Iris-virginica"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>2.1</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.5</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width         species\n",
       "0           5.8          4.0           1.2          0.2     Iris-setosa\n",
       "1           6.8          3.0           5.5          2.1  Iris-virginica\n",
       "2           6.7          3.3           5.7          2.5  Iris-virginica\n",
       "3           4.7          3.2           1.6          0.2     Iris-setosa\n",
       "4           5.4          3.4           1.5          0.4     Iris-setosa"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df.sample(frac=1)\n",
    "df=df.reset_index()\n",
    "df.drop('index',axis=1,inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "      <th>species_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>2.1</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.5</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width         species  \\\n",
       "0           5.8          4.0           1.2          0.2     Iris-setosa   \n",
       "1           6.8          3.0           5.5          2.1  Iris-virginica   \n",
       "2           6.7          3.3           5.7          2.5  Iris-virginica   \n",
       "3           4.7          3.2           1.6          0.2     Iris-setosa   \n",
       "4           5.4          3.4           1.5          0.4     Iris-setosa   \n",
       "\n",
       "   species_num  \n",
       "0            0  \n",
       "1            2  \n",
       "2            2  \n",
       "3            0  \n",
       "4            0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l=[]\n",
    "for i in df.species:\n",
    "    if i=='Iris-setosa':\n",
    "        l.append(0)\n",
    "    elif i=='Iris-virginica':\n",
    "        l.append(2)\n",
    "    else:\n",
    "        l.append(1)\n",
    "df['species_num']=l\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.iloc[:,:-2]\n",
    "y=df['species_num']\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "x_train,x_test,y_train,y_test=tts(x,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB \n",
    "gnb=GaussianNB()\n",
    "gnb.fit(x_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 :  0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print('R^2 : ',gnb.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score :  0.9666666666666667\n",
      "-------------------------------------------------\n",
      "Classification Report \n",
      " ---------------------------------****--------------------------------- \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        12\n",
      "           1       1.00      0.89      0.94         9\n",
      "           2       0.90      1.00      0.95         9\n",
      "\n",
      "    accuracy                           0.97        30\n",
      "   macro avg       0.97      0.96      0.96        30\n",
      "weighted avg       0.97      0.97      0.97        30\n",
      " ---------------------------------****---------------------------------\n",
      "Confusion Matrix \n",
      " ---------------------------------****--------------------------------- \n",
      " [[12  0  0]\n",
      " [ 0  8  1]\n",
      " [ 0  0  9]]\n"
     ]
    }
   ],
   "source": [
    "y_pred=gnb.predict(x_test)\n",
    "print('Accuracy Score : ',accuracy_score(y_test,y_pred))\n",
    "print('-------------------------------------------------')\n",
    "print('Classification Report','\\n','****'.center(70,'-'),'\\n',classification_report(y_test,y_pred),'****'.center(70,'-'))\n",
    "print('Confusion Matrix','\\n','****'.center(70,'-'),'\\n',confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial naive bayes\n",
    "spam email detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>label_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>605</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: enron methanol ; meter # : 988291\\r\\n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2349</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: hpl nom for january 9 , 2001\\r\\n( see...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3624</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: neon retreat\\r\\nho ho ho , we ' re ar...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4685</td>\n",
       "      <td>spam</td>\n",
       "      <td>Subject: photoshop , windows , office . cheap ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2030</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: re : indian springs\\r\\nthis deal is t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 label                                               text  \\\n",
       "0         605   ham  Subject: enron methanol ; meter # : 988291\\r\\n...   \n",
       "1        2349   ham  Subject: hpl nom for january 9 , 2001\\r\\n( see...   \n",
       "2        3624   ham  Subject: neon retreat\\r\\nho ho ho , we ' re ar...   \n",
       "3        4685  spam  Subject: photoshop , windows , office . cheap ...   \n",
       "4        2030   ham  Subject: re : indian springs\\r\\nthis deal is t...   \n",
       "\n",
       "   label_num  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          1  \n",
       "4          0  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv('C:/Users/vikash arya/datascience/datascience_krishnaik/data_sets/spam_ham_dataset.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop unnamed :0 and label column \n",
    "data.drop(['Unnamed: 0','label'],axis=1,inplace=True)\n",
    "# import count vectorizer to convert all uniqe character's count\n",
    "#Convert a collection of text documents to a matrix of token counts\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer=CountVectorizer()\n",
    "x=vectorizer.fit_transform(data['text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split as tts\n",
    "x_train,x_test,y_train,y_test=tts(x,data['label_num'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of features in x 50447 \n",
      " --------------------------------------------------\n",
      "(3878, 50447) (1293, 50447) (3878,) (1293,)\n"
     ]
    }
   ],
   "source": [
    "print('number of features in x',len(vectorizer.get_feature_names()),'\\n','-'.center(50,'-'))\n",
    "print(x_train.shape,x_test.shape,y_train.shape,y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "mnb=MultinomialNB()\n",
    "mnb.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 1, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9853054911059551"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score,classification_report\n",
    "mnb.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score :  0.9853054911059551 \n",
      "\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       917\n",
      "           1       0.98      0.97      0.97       376\n",
      "\n",
      "    accuracy                           0.99      1293\n",
      "   macro avg       0.98      0.98      0.98      1293\n",
      "weighted avg       0.99      0.99      0.99      1293\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred=mnb.predict(x_test)\n",
    "print('Accuracy score : ',accuracy_score(y_test,y_pred),'\\n')\n",
    "print('classification report','\\n',classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([918.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 375.]),\n",
       " array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bernoulli Naive Bayes\n",
    "used when our features follow bernoulli distribution<br>\n",
    "Like MultinomialNB, this classifier is suitable for discrete data. The difference is that while MultinomialNB works with occurrence counts, BernoulliNB is designed for binary/boolean features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make</th>\n",
       "      <th>word_freq_address</th>\n",
       "      <th>word_freq_all</th>\n",
       "      <th>word_freq_3d</th>\n",
       "      <th>word_freq_our</th>\n",
       "      <th>word_freq_over</th>\n",
       "      <th>word_freq_remove</th>\n",
       "      <th>word_freq_internet</th>\n",
       "      <th>word_freq_order</th>\n",
       "      <th>word_freq_mail</th>\n",
       "      <th>...</th>\n",
       "      <th>char_freq_(</th>\n",
       "      <th>char_freq_[</th>\n",
       "      <th>char_freq_!</th>\n",
       "      <th>char_freq_$</th>\n",
       "      <th>char_freq_#</th>\n",
       "      <th>capital_run_length_average</th>\n",
       "      <th>capital_run_length_longest</th>\n",
       "      <th>capital_run_length_total</th>\n",
       "      <th>ham</th>\n",
       "      <th>Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>14.28</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.800</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>True</td>\n",
       "      <td>1947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.357</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.892</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>19</td>\n",
       "      <td>172</td>\n",
       "      <td>False</td>\n",
       "      <td>2159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.43</td>\n",
       "      <td>...</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.477</td>\n",
       "      <td>8</td>\n",
       "      <td>65</td>\n",
       "      <td>False</td>\n",
       "      <td>4223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.444</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.800</td>\n",
       "      <td>7</td>\n",
       "      <td>28</td>\n",
       "      <td>True</td>\n",
       "      <td>2624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.17</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.551</td>\n",
       "      <td>10</td>\n",
       "      <td>45</td>\n",
       "      <td>True</td>\n",
       "      <td>2743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.022</td>\n",
       "      <td>3.482</td>\n",
       "      <td>5</td>\n",
       "      <td>5902</td>\n",
       "      <td>True</td>\n",
       "      <td>3451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.302</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.241</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.166</td>\n",
       "      <td>18</td>\n",
       "      <td>143</td>\n",
       "      <td>False</td>\n",
       "      <td>464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.00</td>\n",
       "      <td>3.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.03</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.769</td>\n",
       "      <td>21</td>\n",
       "      <td>36</td>\n",
       "      <td>True</td>\n",
       "      <td>3219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.09</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.722</td>\n",
       "      <td>17</td>\n",
       "      <td>267</td>\n",
       "      <td>True</td>\n",
       "      <td>3007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.142</td>\n",
       "      <td>4</td>\n",
       "      <td>56</td>\n",
       "      <td>True</td>\n",
       "      <td>1549</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
       "0            0.00              14.28           0.00           0.0   \n",
       "1            0.00               0.00           1.00           0.0   \n",
       "2            0.00               0.00           0.00           0.0   \n",
       "3            0.00               0.00           0.00           0.0   \n",
       "4            0.00               0.00           0.00           0.0   \n",
       "5            0.00               0.00           0.00           0.0   \n",
       "6            0.00               0.00           0.37           0.0   \n",
       "7            0.00               3.03           0.00           0.0   \n",
       "8            0.09               0.00           0.48           0.0   \n",
       "9            0.00               0.00           0.66           0.0   \n",
       "\n",
       "   word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
       "0           0.00            0.00              0.00                0.00   \n",
       "1           0.50            0.00              0.00                0.00   \n",
       "2           0.00            0.00              0.00                1.29   \n",
       "3           0.00            0.00              0.00                0.00   \n",
       "4           1.17            0.00              0.00                0.00   \n",
       "5           0.00            0.00              0.00                0.00   \n",
       "6           0.00            0.00              0.37                0.00   \n",
       "7           0.00            0.00              0.00                0.00   \n",
       "8           0.00            0.29              0.00                0.00   \n",
       "9           0.00            0.66              0.00                0.00   \n",
       "\n",
       "   word_freq_order  word_freq_mail  ...  char_freq_(  char_freq_[  \\\n",
       "0              0.0            0.00  ...        0.000        0.000   \n",
       "1              0.0            0.50  ...        0.357        0.000   \n",
       "2              0.0            0.43  ...        0.124        0.000   \n",
       "3              0.0            0.00  ...        0.000        0.000   \n",
       "4              0.0            1.17  ...        0.000        0.000   \n",
       "5              0.0            0.00  ...        0.022        0.019   \n",
       "6              0.0            0.00  ...        0.302        0.000   \n",
       "7              0.0            3.03  ...        0.000        0.000   \n",
       "8              0.0            0.09  ...        0.030        0.000   \n",
       "9              0.0            0.00  ...        0.000        0.000   \n",
       "\n",
       "   char_freq_!  char_freq_$  char_freq_#  capital_run_length_average  \\\n",
       "0        0.000        0.000        0.000                       1.800   \n",
       "1        0.892        0.000        0.000                       2.000   \n",
       "2        0.310        0.062        0.000                       1.477   \n",
       "3        0.444        0.000        0.000                       2.800   \n",
       "4        0.000        0.000        0.000                       1.551   \n",
       "5        0.022        0.022        0.022                       3.482   \n",
       "6        0.241        0.060        0.000                       2.166   \n",
       "7        0.000        0.000        0.000                       2.769   \n",
       "8        0.000        0.046        0.000                       1.722   \n",
       "9        0.000        0.000        0.000                       1.142   \n",
       "\n",
       "   capital_run_length_longest  capital_run_length_total    ham    Id  \n",
       "0                           5                         9   True  1947  \n",
       "1                          19                       172  False  2159  \n",
       "2                           8                        65  False  4223  \n",
       "3                           7                        28   True  2624  \n",
       "4                          10                        45   True  2743  \n",
       "5                           5                      5902   True  3451  \n",
       "6                          18                       143  False   464  \n",
       "7                          21                        36   True  3219  \n",
       "8                          17                       267   True  3007  \n",
       "9                           4                        56   True  1549  \n",
       "\n",
       "[10 rows x 59 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt=pd.read_csv('C:/Users/vikash arya/datascience/datascience_krishnaik/data_sets/spambase/train_data.csv')\n",
    "dt.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=dt.iloc[:,:-5]\n",
    "y=dt.ham\n",
    "x_train,x_test,y_train,y_test=tts(x,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB()"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "bnb=BernoulliNB()\n",
    "bnb.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8940217391304348"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnb.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score :  0.8940217391304348 \n",
      "\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.88      0.85      0.86       288\n",
      "        True       0.91      0.92      0.91       448\n",
      "\n",
      "    accuracy                           0.89       736\n",
      "   macro avg       0.89      0.89      0.89       736\n",
      "weighted avg       0.89      0.89      0.89       736\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred=bnb.predict(x_test)\n",
    "print('Accuracy score : ',accuracy_score(y_test,y_pred),'\\n')\n",
    "print('classification report','\\n',classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
